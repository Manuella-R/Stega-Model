{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéØ Memory-Optimized Watermarking Model - 85-90% Accuracy\n",
        "\n",
        "## ‚ö° Optimized for T4 GPU (15GB)\n",
        "\n",
        "**Key Optimizations:**\n",
        "- ‚úÖ Smaller batch size (16 instead of 32)\n",
        "- ‚úÖ Gradient accumulation (effective batch size = 32)\n",
        "- ‚úÖ Mixed precision training (FP16)\n",
        "- ‚úÖ Memory-efficient perceptual loss\n",
        "- ‚úÖ Automatic memory clearing\n",
        "\n",
        "**Expected Results:** 85-90% accuracy in ~40-50 minutes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Install packages\n",
        "!pip install -q torch torchvision matplotlib opencv-python-headless scikit-image scikit-learn PyWavelets Pillow tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ‚ö†Ô∏è CHANGE THIS PATH ‚ö†Ô∏è\n",
        "ROOT_IMAGES = '/content/drive/MyDrive/project/JPEGImages'\n",
        "\n",
        "# Memory-optimized configuration\n",
        "CONFIG = {\n",
        "    'epochs': 20,\n",
        "    'batch_size': 16,          # ‚úÖ Reduced from 32 to save memory\n",
        "    'accumulation_steps': 2,   # ‚úÖ Gradient accumulation (effective batch = 32)\n",
        "    'lr': 1e-3,\n",
        "    'payload_len': 64,\n",
        "    'train_n': 10000,\n",
        "    'val_n': 2000,\n",
        "    'test_n': 2000,\n",
        "    'early_stop_patience': 5,\n",
        "    'image_size': 256,\n",
        "    'use_amp': True,           # ‚úÖ Mixed precision (FP16) for memory savings\n",
        "}\n",
        "\n",
        "print('üìÇ Image directory:', ROOT_IMAGES)\n",
        "print('\\n‚öôÔ∏è Memory-Optimized Configuration:')\n",
        "for k, v in CONFIG.items():\n",
        "    print(f'  {k:20s} = {v}')\n",
        "print(f\"\\n  Effective batch size: {CONFIG['batch_size'] * CONFIG['accumulation_steps']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os\n",
        "import gc\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from pathlib import Path\n",
        "import random\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'üñ•Ô∏è  Device: {device}')\n",
        "if device == 'cuda':\n",
        "    print(f'    GPU: {torch.cuda.get_device_name(0)}')\n",
        "    total_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    print(f'    Total Memory: {total_mem:.1f} GB')\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "# Set seeds\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "\n",
        "print('\\n‚úÖ Setup complete!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Improved Encoder (same as before)\n",
        "class ImprovedEncoder(nn.Module):\n",
        "    def __init__(self, payload_len=64, hidden=64):\n",
        "        super().__init__()\n",
        "        self.payload_len = payload_len\n",
        "        \n",
        "        self.payload_embed = nn.Sequential(\n",
        "            nn.Linear(payload_len, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 16*16*8)\n",
        "        )\n",
        "        \n",
        "        self.down1 = nn.Sequential(\n",
        "            nn.Conv2d(3 + 8, hidden, 3, padding=1),\n",
        "            nn.BatchNorm2d(hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(hidden, hidden, 3, padding=1),\n",
        "            nn.BatchNorm2d(hidden),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        \n",
        "        self.down2 = nn.Sequential(\n",
        "            nn.Conv2d(hidden, hidden*2, 3, padding=1),\n",
        "            nn.BatchNorm2d(hidden*2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(hidden*2, hidden*2, 3, padding=1),\n",
        "            nn.BatchNorm2d(hidden*2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        self.down3 = nn.Sequential(\n",
        "            nn.Conv2d(hidden*2, hidden*4, 3, padding=1),\n",
        "            nn.BatchNorm2d(hidden*4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(hidden*4, hidden*4, 3, padding=1),\n",
        "            nn.BatchNorm2d(hidden*4),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        self.up1 = nn.ConvTranspose2d(hidden*4, hidden*2, 2, stride=2)\n",
        "        self.up_conv1 = nn.Sequential(\n",
        "            nn.Conv2d(hidden*4, hidden*2, 3, padding=1),\n",
        "            nn.BatchNorm2d(hidden*2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        self.up2 = nn.ConvTranspose2d(hidden*2, hidden, 2, stride=2)\n",
        "        self.up_conv2 = nn.Sequential(\n",
        "            nn.Conv2d(hidden*2, hidden, 3, padding=1),\n",
        "            nn.BatchNorm2d(hidden),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        self.out_conv = nn.Sequential(\n",
        "            nn.Conv2d(hidden, hidden, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(hidden, 3, 1)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x, payload):\n",
        "        B, _, H, W = x.shape\n",
        "        \n",
        "        p_feat = self.payload_embed(payload)\n",
        "        p_feat = p_feat.view(B, 8, 16, 16)\n",
        "        p_feat = F.interpolate(p_feat, size=(H, W), mode='bilinear', align_corners=False)\n",
        "        \n",
        "        x_in = torch.cat([x, p_feat], dim=1)\n",
        "        \n",
        "        d1 = self.down1(x_in)\n",
        "        p1 = self.pool(d1)\n",
        "        \n",
        "        d2 = self.down2(p1)\n",
        "        p2 = self.pool(d2)\n",
        "        \n",
        "        d3 = self.down3(p2)\n",
        "        \n",
        "        u1 = self.up1(d3)\n",
        "        u1 = torch.cat([u1, d2], dim=1)\n",
        "        u1 = self.up_conv1(u1)\n",
        "        \n",
        "        u2 = self.up2(u1)\n",
        "        u2 = torch.cat([u2, d1], dim=1)\n",
        "        u2 = self.up_conv2(u2)\n",
        "        \n",
        "        res = torch.tanh(self.out_conv(u2)) * 0.05\n",
        "        \n",
        "        return res\n",
        "\n",
        "print('‚úÖ Encoder defined')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Improved Decoder (same as before)\n",
        "class ImprovedDecoder(nn.Module):\n",
        "    def __init__(self, payload_len=64, hidden=64):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, hidden, 3, padding=1),\n",
        "            nn.BatchNorm2d(hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(hidden, hidden, 3, padding=1),\n",
        "            nn.BatchNorm2d(hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        \n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(hidden, hidden*2, 3, padding=1),\n",
        "            nn.BatchNorm2d(hidden*2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(hidden*2, hidden*2, 3, padding=1),\n",
        "            nn.BatchNorm2d(hidden*2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        \n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(hidden*2, hidden*4, 3, padding=1),\n",
        "            nn.BatchNorm2d(hidden*4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(hidden*4, hidden*4, 3, padding=1),\n",
        "            nn.BatchNorm2d(hidden*4),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d((8, 8))\n",
        "        )\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(hidden*4*8*8, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, payload_len)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        f1 = self.conv1(x)\n",
        "        f2 = self.conv2(f1)\n",
        "        f3 = self.conv3(f2)\n",
        "        logits = self.fc(f3)\n",
        "        return logits\n",
        "\n",
        "print('‚úÖ Decoder defined')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Attack Pipeline (same as before)\n",
        "class ImprovedAttack(nn.Module):\n",
        "    def __init__(self, p_jpeg=0.7):\n",
        "        super().__init__()\n",
        "        self.p_jpeg = p_jpeg\n",
        "        \n",
        "    def forward(self, imgs):\n",
        "        x = imgs\n",
        "        \n",
        "        # Resize\n",
        "        if random.random() < 0.95:\n",
        "            scales = torch.empty(x.size(0)).uniform_(0.75, 0.95).tolist()\n",
        "            out = torch.zeros_like(x)\n",
        "            for i, s in enumerate(scales):\n",
        "                h, w = x.shape[2], x.shape[3]\n",
        "                nh, nw = max(1, int(h*s)), max(1, int(w*s))\n",
        "                small = F.interpolate(x[i:i+1], size=(nh, nw), mode='bilinear', align_corners=False)\n",
        "                back = F.interpolate(small, size=(h, w), mode='bilinear', align_corners=False)\n",
        "                out[i:i+1] = back\n",
        "            x = out\n",
        "        \n",
        "        # Rotation\n",
        "        if random.random() < 0.6:\n",
        "            angles = torch.empty(x.size(0)).uniform_(-5, 5).tolist()\n",
        "            theta_batch = []\n",
        "            for ang in angles:\n",
        "                rad = np.deg2rad(ang)\n",
        "                theta = torch.tensor([\n",
        "                    [np.cos(rad), -np.sin(rad), 0.0],\n",
        "                    [np.sin(rad), np.cos(rad), 0.0]\n",
        "                ], dtype=torch.float)\n",
        "                theta_batch.append(theta.unsqueeze(0))\n",
        "            theta_batch = torch.cat(theta_batch, dim=0).to(x.device)\n",
        "            grid = F.affine_grid(theta_batch, x.size(), align_corners=False)\n",
        "            x = F.grid_sample(x, grid, padding_mode='border', align_corners=False)\n",
        "        \n",
        "        # Blur\n",
        "        if random.random() < 0.8:\n",
        "            k = random.choice([3, 5])\n",
        "            kernel = torch.tensor(cv2.getGaussianKernel(k, k/3).astype(np.float32))\n",
        "            kernel2 = kernel @ kernel.T\n",
        "            kernel2 = kernel2 / kernel2.sum()\n",
        "            k_t = kernel2.unsqueeze(0).unsqueeze(0).to(x.device)\n",
        "            pad = k // 2\n",
        "            out = F.pad(x, (pad, pad, pad, pad), mode='reflect')\n",
        "            out_c = []\n",
        "            for c in range(3):\n",
        "                out_c.append(F.conv2d(out[:, c:c+1, :, :], k_t, padding=0))\n",
        "            x = torch.cat(out_c, dim=1)\n",
        "        \n",
        "        # Noise\n",
        "        if random.random() < 0.9:\n",
        "            noise = torch.randn_like(x) * random.uniform(0.003, 0.01)\n",
        "            x = torch.clamp(x + noise, 0, 1)\n",
        "        \n",
        "        # JPEG\n",
        "        if random.random() < self.p_jpeg:\n",
        "            x_np = (x.detach().cpu().numpy() * 255).astype(np.uint8)\n",
        "            out_batch = []\n",
        "            for i in range(x_np.shape[0]):\n",
        "                img_bgr = cv2.cvtColor(x_np[i].transpose(1, 2, 0), cv2.COLOR_RGB2BGR)\n",
        "                q = random.randint(70, 95)\n",
        "                _, enc = cv2.imencode('.jpg', img_bgr, [int(cv2.IMWRITE_JPEG_QUALITY), q])\n",
        "                dec = cv2.imdecode(enc, cv2.IMREAD_COLOR)\n",
        "                dec_rgb = cv2.cvtColor(dec, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
        "                out_batch.append(dec_rgb)\n",
        "            x = torch.from_numpy(np.stack(out_batch, axis=0)).permute(0, 3, 1, 2).to(imgs.device).float()\n",
        "        \n",
        "        return x\n",
        "\n",
        "print('‚úÖ Attack pipeline defined')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, paths, image_size=256):\n",
        "        self.paths = [str(p) for p in paths]\n",
        "        self.image_size = image_size\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            img = io.imread(self.paths[idx])\n",
        "            if img.ndim == 2:\n",
        "                img = np.stack([img, img, img], axis=-1)\n",
        "            if img.shape[2] == 4:\n",
        "                img = img[:, :, :3]\n",
        "            \n",
        "            img = (img.astype(np.float32) / 255.0) if img.max() > 1.0 else img.astype(np.float32)\n",
        "            \n",
        "            H, W = img.shape[:2]\n",
        "            side = min(H, W)\n",
        "            cy, cx = H // 2, W // 2\n",
        "            img_crop = img[cy-side//2:cy-side//2+side, cx-side//2:cx-side//2+side]\n",
        "            img_resized = cv2.resize(img_crop, (self.image_size, self.image_size), interpolation=cv2.INTER_AREA)\n",
        "            \n",
        "            img_t = torch.from_numpy(img_resized).permute(2, 0, 1).float()\n",
        "            return img_t\n",
        "        except Exception as e:\n",
        "            return torch.zeros(3, self.image_size, self.image_size)\n",
        "\n",
        "def create_datasets(root_dir, train_n=10000, val_n=2000, test_n=2000, seed=42):\n",
        "    paths = list(Path(root_dir).glob('**/*.jpg')) + list(Path(root_dir).glob('**/*.png'))\n",
        "    random.Random(seed).shuffle(paths)\n",
        "    \n",
        "    total_needed = train_n + val_n + test_n\n",
        "    available = len(paths)\n",
        "    \n",
        "    print(f'Found {available} images in {root_dir}')\n",
        "    \n",
        "    if available < total_needed:\n",
        "        print(f'‚ö†Ô∏è  Warning: Only {available} images available')\n",
        "        ratio = available / total_needed\n",
        "        train_n = int(train_n * ratio)\n",
        "        val_n = int(val_n * ratio)\n",
        "        test_n = available - train_n - val_n\n",
        "    \n",
        "    train_paths = paths[:train_n]\n",
        "    val_paths = paths[train_n:train_n+val_n]\n",
        "    test_paths = paths[train_n+val_n:train_n+val_n+test_n]\n",
        "    \n",
        "    print(f'\\nDataset splits:')\n",
        "    print(f'  Train: {len(train_paths):,} images')\n",
        "    print(f'  Val:   {len(val_paths):,} images')\n",
        "    print(f'  Test:  {len(test_paths):,} images')\n",
        "    \n",
        "    return train_paths, val_paths, test_paths\n",
        "\n",
        "print('‚úÖ Dataset utilities defined')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ Memory-Optimized Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model_memory_efficient(root_images, epochs=20, batch_size=16, accumulation_steps=2,\n",
        "                                  lr=1e-3, payload_len=64, train_n=10000, val_n=2000, \n",
        "                                  test_n=2000, early_stop_patience=5, use_amp=True):\n",
        "    \"\"\"\n",
        "    Memory-optimized training with:\n",
        "    - Gradient accumulation\n",
        "    - Mixed precision (FP16)\n",
        "    - Simplified perceptual loss\n",
        "    - Memory cleanup\n",
        "    \"\"\"\n",
        "    \n",
        "    print('='*70)\n",
        "    print('MEMORY-OPTIMIZED TRAINING')\n",
        "    print('='*70)\n",
        "    print(f'\\nBatch size: {batch_size}')\n",
        "    print(f'Accumulation steps: {accumulation_steps}')\n",
        "    print(f'Effective batch size: {batch_size * accumulation_steps}')\n",
        "    print(f'Mixed precision: {use_amp}\\n')\n",
        "    \n",
        "    # Clear memory\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    \n",
        "    # Create datasets\n",
        "    train_paths, val_paths, test_paths = create_datasets(\n",
        "        root_images, train_n=train_n, val_n=val_n, test_n=test_n\n",
        "    )\n",
        "    \n",
        "    train_ds = ImageDataset(train_paths)\n",
        "    val_ds = ImageDataset(val_paths)\n",
        "    test_ds = ImageDataset(test_paths)\n",
        "    \n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, \n",
        "                              num_workers=2, pin_memory=True, drop_last=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, \n",
        "                            num_workers=2, pin_memory=True)\n",
        "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, \n",
        "                             num_workers=2, pin_memory=True)\n",
        "    \n",
        "    # Initialize models\n",
        "    print('\\nüèóÔ∏è  Initializing models...')\n",
        "    encoder = ImprovedEncoder(payload_len=payload_len).to(device)\n",
        "    decoder = ImprovedDecoder(payload_len=payload_len).to(device)\n",
        "    attack = ImprovedAttack(p_jpeg=0.7).to(device)\n",
        "    \n",
        "    # Optimizer\n",
        "    params = list(encoder.parameters()) + list(decoder.parameters())\n",
        "    optimizer = torch.optim.AdamW(params, lr=lr, weight_decay=1e-5)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-5)\n",
        "    \n",
        "    # Mixed precision scaler\n",
        "    scaler = GradScaler() if use_amp else None\n",
        "    \n",
        "    # Simplified perceptual loss (no VGG to save memory)\n",
        "    def simple_perceptual_loss(x, y):\n",
        "        \"\"\"Lightweight perceptual loss using gradient magnitude\"\"\"\n",
        "        def get_gradients(img):\n",
        "            dx = img[:, :, :, 1:] - img[:, :, :, :-1]\n",
        "            dy = img[:, :, 1:, :] - img[:, :, :-1, :]\n",
        "            return dx, dy\n",
        "        \n",
        "        dx_x, dy_x = get_gradients(x)\n",
        "        dx_y, dy_y = get_gradients(y)\n",
        "        \n",
        "        return F.mse_loss(dx_x, dx_y) + F.mse_loss(dy_x, dy_y)\n",
        "    \n",
        "    # Training history\n",
        "    history = {\n",
        "        'train_loss': [], 'train_acc': [],\n",
        "        'val_loss': [], 'val_acc': [],\n",
        "        'val_precision': [], 'val_recall': [], 'val_f1': []\n",
        "    }\n",
        "    \n",
        "    best_val_acc = 0.0\n",
        "    no_improve = 0\n",
        "    \n",
        "    print(f'\\nüéØ Starting training for {epochs} epochs...')\n",
        "    print('='*70)\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        # ========== TRAINING ==========\n",
        "        encoder.train()\n",
        "        decoder.train()\n",
        "        \n",
        "        train_losses = []\n",
        "        train_accs = []\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\")\n",
        "        for batch_idx, imgs in enumerate(pbar):\n",
        "            imgs = imgs.to(device)\n",
        "            B = imgs.size(0)\n",
        "            \n",
        "            payload = torch.randint(0, 2, (B, payload_len)).float().to(device)\n",
        "            \n",
        "            # Mixed precision forward pass\n",
        "            with autocast(enabled=use_amp):\n",
        "                residual = encoder(imgs, payload)\n",
        "                watermarked = torch.clamp(imgs + residual, 0.0, 1.0)\n",
        "                attacked = attack(watermarked)\n",
        "                logits = decoder(attacked)\n",
        "                \n",
        "                # Losses\n",
        "                bce_loss = F.binary_cross_entropy_with_logits(logits, payload)\n",
        "                mse_loss = F.mse_loss(watermarked, imgs)\n",
        "                perc_loss = simple_perceptual_loss(watermarked, imgs)\n",
        "                \n",
        "                # Combined loss (normalized by accumulation steps)\n",
        "                loss = (bce_loss + 0.1 * mse_loss + 0.1 * perc_loss) / accumulation_steps\n",
        "            \n",
        "            # Backward pass\n",
        "            if use_amp:\n",
        "                scaler.scale(loss).backward()\n",
        "            else:\n",
        "                loss.backward()\n",
        "            \n",
        "            # Update weights after accumulation\n",
        "            if (batch_idx + 1) % accumulation_steps == 0:\n",
        "                if use_amp:\n",
        "                    scaler.unscale_(optimizer)\n",
        "                    torch.nn.utils.clip_grad_norm_(params, max_norm=1.0)\n",
        "                    scaler.step(optimizer)\n",
        "                    scaler.update()\n",
        "                else:\n",
        "                    torch.nn.utils.clip_grad_norm_(params, max_norm=1.0)\n",
        "                    optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "            \n",
        "            # Compute accuracy\n",
        "            with torch.no_grad():\n",
        "                pred_bits = (torch.sigmoid(logits) > 0.5).float()\n",
        "                acc = (pred_bits == payload).float().mean().item()\n",
        "            \n",
        "            train_losses.append(loss.item() * accumulation_steps)\n",
        "            train_accs.append(acc)\n",
        "            \n",
        "            # Show memory usage\n",
        "            if batch_idx % 50 == 0 and torch.cuda.is_available():\n",
        "                mem_used = torch.cuda.memory_allocated() / 1e9\n",
        "                mem_cached = torch.cuda.memory_reserved() / 1e9\n",
        "                pbar.set_postfix({\n",
        "                    'loss': f'{loss.item()*accumulation_steps:.4f}',\n",
        "                    'acc': f'{acc*100:.1f}%',\n",
        "                    'mem': f'{mem_used:.1f}GB'\n",
        "                })\n",
        "            else:\n",
        "                pbar.set_postfix({\n",
        "                    'loss': f'{loss.item()*accumulation_steps:.4f}',\n",
        "                    'acc': f'{acc*100:.1f}%'\n",
        "                })\n",
        "        \n",
        "        avg_train_loss = np.mean(train_losses)\n",
        "        avg_train_acc = np.mean(train_accs)\n",
        "        history['train_loss'].append(avg_train_loss)\n",
        "        history['train_acc'].append(avg_train_acc)\n",
        "        \n",
        "        # Clear cache after training\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "        # ========== VALIDATION ==========\n",
        "        encoder.eval()\n",
        "        decoder.eval()\n",
        "        \n",
        "        val_losses = []\n",
        "        all_preds = []\n",
        "        all_targets = []\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for imgs in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]  \", leave=False):\n",
        "                imgs = imgs.to(device)\n",
        "                B = imgs.size(0)\n",
        "                \n",
        "                payload = torch.randint(0, 2, (B, payload_len)).float().to(device)\n",
        "                \n",
        "                with autocast(enabled=use_amp):\n",
        "                    residual = encoder(imgs, payload)\n",
        "                    watermarked = torch.clamp(imgs + residual, 0.0, 1.0)\n",
        "                    attacked = attack(watermarked)\n",
        "                    logits = decoder(attacked)\n",
        "                    bce_loss = F.binary_cross_entropy_with_logits(logits, payload)\n",
        "                \n",
        "                val_losses.append(bce_loss.item())\n",
        "                \n",
        "                preds = (torch.sigmoid(logits) > 0.5).long().cpu().numpy().reshape(-1)\n",
        "                targs = payload.long().cpu().numpy().reshape(-1)\n",
        "                \n",
        "                all_preds.extend(preds.tolist())\n",
        "                all_targets.extend(targs.tolist())\n",
        "        \n",
        "        # Compute metrics\n",
        "        avg_val_loss = np.mean(val_losses)\n",
        "        val_acc = accuracy_score(all_targets, all_preds)\n",
        "        val_prec = precision_score(all_targets, all_preds, zero_division=0)\n",
        "        val_rec = recall_score(all_targets, all_preds, zero_division=0)\n",
        "        val_f1 = f1_score(all_targets, all_preds, zero_division=0)\n",
        "        \n",
        "        history['val_loss'].append(avg_val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        history['val_precision'].append(val_prec)\n",
        "        history['val_recall'].append(val_rec)\n",
        "        history['val_f1'].append(val_f1)\n",
        "        \n",
        "        # Print epoch summary\n",
        "        print(f'\\nEpoch {epoch+1}/{epochs}:')\n",
        "        print(f'  Train - Loss: {avg_train_loss:.4f}, Acc: {avg_train_acc*100:.2f}%')\n",
        "        print(f'  Val   - Loss: {avg_val_loss:.4f}, Acc: {val_acc*100:.2f}%, F1: {val_f1:.3f}')\n",
        "        \n",
        "        # Memory stats\n",
        "        if torch.cuda.is_available():\n",
        "            mem_used = torch.cuda.memory_allocated() / 1e9\n",
        "            mem_max = torch.cuda.max_memory_allocated() / 1e9\n",
        "            print(f'  Memory - Used: {mem_used:.2f}GB, Peak: {mem_max:.2f}GB')\n",
        "            torch.cuda.reset_peak_memory_stats()\n",
        "        \n",
        "        # Learning rate scheduling\n",
        "        scheduler.step()\n",
        "        \n",
        "        # Early stopping and checkpoint\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            no_improve = 0\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'encoder': encoder.state_dict(),\n",
        "                'decoder': decoder.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'val_acc': val_acc,\n",
        "            }, '/content/best_model_checkpoint.pt')\n",
        "            print(f'  ‚úÖ New best model saved! (Val Acc: {val_acc*100:.2f}%)')\n",
        "        else:\n",
        "            no_improve += 1\n",
        "            if no_improve >= early_stop_patience:\n",
        "                print(f'\\nüõë Early stopping triggered')\n",
        "                break\n",
        "        \n",
        "        print('-'*70)\n",
        "        \n",
        "        # Clear cache after epoch\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "    \n",
        "    # Load best model\n",
        "    checkpoint = torch.load('/content/best_model_checkpoint.pt')\n",
        "    encoder.load_state_dict(checkpoint['encoder'])\n",
        "    decoder.load_state_dict(checkpoint['decoder'])\n",
        "    \n",
        "    # Test evaluation\n",
        "    print('\\n' + '='*70)\n",
        "    print('FINAL TEST EVALUATION')\n",
        "    print('='*70)\n",
        "    \n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "    \n",
        "    all_test_preds = []\n",
        "    all_test_targets = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for imgs in tqdm(test_loader, desc=\"Testing\"):\n",
        "            imgs = imgs.to(device)\n",
        "            B = imgs.size(0)\n",
        "            \n",
        "            payload = torch.randint(0, 2, (B, payload_len)).float().to(device)\n",
        "            \n",
        "            with autocast(enabled=use_amp):\n",
        "                residual = encoder(imgs, payload)\n",
        "                watermarked = torch.clamp(imgs + residual, 0.0, 1.0)\n",
        "                attacked = attack(watermarked)\n",
        "                logits = decoder(attacked)\n",
        "            \n",
        "            preds = (torch.sigmoid(logits) > 0.5).long().cpu().numpy().reshape(-1)\n",
        "            targs = payload.long().cpu().numpy().reshape(-1)\n",
        "            \n",
        "            all_test_preds.extend(preds.tolist())\n",
        "            all_test_targets.extend(targs.tolist())\n",
        "    \n",
        "    test_acc = accuracy_score(all_test_targets, all_test_preds)\n",
        "    test_prec = precision_score(all_test_targets, all_test_preds, zero_division=0)\n",
        "    test_rec = recall_score(all_test_targets, all_test_preds, zero_division=0)\n",
        "    test_f1 = f1_score(all_test_targets, all_test_preds, zero_division=0)\n",
        "    \n",
        "    print(f'\\nüìä Test Results:')\n",
        "    print(f'   Accuracy:  {test_acc*100:.2f}%')\n",
        "    print(f'   Precision: {test_prec:.4f}')\n",
        "    print(f'   Recall:    {test_rec:.4f}')\n",
        "    print(f'   F1-Score:  {test_f1:.4f}')\n",
        "    \n",
        "    if test_acc >= 0.85:\n",
        "        print(f'\\nüéâ SUCCESS! Achieved target accuracy')\n",
        "    elif test_acc >= 0.75:\n",
        "        print(f'\\n‚ö†Ô∏è  Close to target')\n",
        "    else:\n",
        "        print(f'\\n‚ùå Below target')\n",
        "    \n",
        "    print('\\n' + '='*70)\n",
        "    \n",
        "    return encoder, decoder, history\n",
        "\n",
        "print('‚úÖ Memory-optimized training function defined')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ‚ñ∂Ô∏è RUN TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üöÄ START TRAINING\n",
        "encoder, decoder, history = train_model_memory_efficient(\n",
        "    root_images=ROOT_IMAGES,\n",
        "    epochs=CONFIG['epochs'],\n",
        "    batch_size=CONFIG['batch_size'],\n",
        "    accumulation_steps=CONFIG['accumulation_steps'],\n",
        "    lr=CONFIG['lr'],\n",
        "    payload_len=CONFIG['payload_len'],\n",
        "    train_n=CONFIG['train_n'],\n",
        "    val_n=CONFIG['val_n'],\n",
        "    test_n=CONFIG['test_n'],\n",
        "    early_stop_patience=CONFIG['early_stop_patience'],\n",
        "    use_amp=CONFIG['use_amp']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "axes[0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
        "axes[0].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].set_title('Training and Validation Loss', fontweight='bold')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1].plot([a*100 for a in history['train_acc']], label='Train Acc', linewidth=2)\n",
        "axes[1].plot([a*100 for a in history['val_acc']], label='Val Acc', linewidth=2)\n",
        "axes[1].axhline(y=85, color='g', linestyle='--', label='Target', linewidth=2)\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Accuracy (%)')\n",
        "axes[1].set_title('Training and Validation Accuracy', fontweight='bold')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "axes[2].plot([f*100 for f in history['val_f1']], label='F1', linewidth=2)\n",
        "axes[2].plot([p*100 for p in history['val_precision']], label='Precision', linewidth=2)\n",
        "axes[2].plot([r*100 for r in history['val_recall']], label='Recall', linewidth=2)\n",
        "axes[2].set_xlabel('Epoch')\n",
        "axes[2].set_ylabel('Score (%)')\n",
        "axes[2].set_title('Validation Metrics', fontweight='bold')\n",
        "axes[2].legend()\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/training_history.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "print('‚úÖ Saved to /content/training_history.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download files\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# Save to Drive\n",
        "shutil.copy('/content/best_model_checkpoint.pt', '/content/drive/MyDrive/watermark_model.pt')\n",
        "shutil.copy('/content/training_history.png', '/content/drive/MyDrive/training_history.png')\n",
        "print('‚úÖ Saved to Google Drive')\n",
        "\n",
        "# Download\n",
        "files.download('/content/best_model_checkpoint.pt')\n",
        "files.download('/content/training_history.png')\n",
        "print('‚úÖ Files downloaded!')"
      ]
    }
  ]
}
